# uvicorn app:app --reload --host 127.0.0.1 --port 8000

import sys, os
sys.stdout.reconfigure(encoding='utf-8')
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse
import tempfile, subprocess, json, datetime, torch, cv2, mediapipe as mp, numpy as np

# âœ… ëª¨ë¸ ì„í¬íŠ¸
from models.hybrid_encodeco_lstm import HybridDecoderFlow
from dataset.RepCountA_Loader import RepCountADataset

# -------------------------------------------------------------------
# ê¸°ë³¸ ì„¤ì •
# -------------------------------------------------------------------
app = FastAPI(title="Fitness AI Server", version="1.0.0")
BASE_DIR = os.path.dirname(os.path.abspath(__file__))  # /app/transRAC-main/tools/last
ROOT_DIR = os.path.abspath(os.path.join(BASE_DIR, "../../.."))  # /app/transRAC-main
# ìƒëŒ€ê²½ë¡œ ê¸°ë°˜ ì„¤ì • (Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ /app ê¸°ì¤€)
SCRIPTS_DIR = os.path.join(BASE_DIR)
MODEL_PATH  = os.path.join(ROOT_DIR, "models", "best_hybrid_decoderflow_7class.pt")
CSV_PATH    = os.path.join(ROOT_DIR, "RepCountA", "annotation", "valid_7class.csv")
NPZ_DIR     = os.path.join(ROOT_DIR, "RepCountA", "npz_all")
sys.path.append(ROOT_DIR)
sys.path.append(os.path.join(ROOT_DIR, "TransRAC_main"))

# âœ… 7ê°œ ìš´ë™ ìŠ¤í¬ë¦½íŠ¸ ë“±ë¡
SCRIPTS = {
    "pushup":     os.path.join(SCRIPTS_DIR, "mediapipe_pushup.py"),
    "squat":      os.path.join(SCRIPTS_DIR, "mediapipe_squat.py"),
    "pullup":     os.path.join(SCRIPTS_DIR, "mediapipe_pullup.py"),
    "jumpingjack":   os.path.join(SCRIPTS_DIR, "mediapipe_jumpingjack.py"),
    "frontraise": os.path.join(SCRIPTS_DIR, "mediapipe_frontraise.py"),
    "benchpress": os.path.join(SCRIPTS_DIR, "mediapipe_benchpress.py"),
    "situp":      os.path.join(SCRIPTS_DIR, "mediapipe_situp.py"),
}

# -------------------------------------------------------------------
# ë¶„ë¥˜ ëª¨ë¸ ì¤€ë¹„
# -------------------------------------------------------------------
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
NUM_CLASSES = 7

print("ğŸ§  ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
model = HybridDecoderFlow(
    input_dim=132, hidden_dim=256, num_heads=4, num_layers=2, num_classes=NUM_CLASSES
).to(DEVICE)

model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
model.eval()
print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

# âœ… ë¼ë²¨ ë§µ ë¶ˆëŸ¬ì˜¤ê¸°
tmp_dataset = RepCountADataset(
    npz_dir=NPZ_DIR,
    annotation_csv=CSV_PATH,
    num_frames=64,
    normalize=True
)
inv_label_map = {v: k for k, v in tmp_dataset.label_map.items()}

# -------------------------------------------------------------------
# Pose ì¶”ì¶œ í•¨ìˆ˜
# -------------------------------------------------------------------
def extract_pose_from_video(video_path, num_frames=64):
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(static_image_mode=False,
                        min_detection_confidence=0.5,
                        min_tracking_confidence=0.5)

    cap = cv2.VideoCapture(video_path)
    frames = []

    while True:
        ret, frame = cap.read()
        if not ret:
            break
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(rgb)
        if results.pose_landmarks:
            pts = np.array([[lm.x, lm.y, lm.z, lm.visibility] for lm in results.pose_landmarks.landmark])
        else:
            pts = np.zeros((33, 4))
        frames.append(pts)

    cap.release()
    pose.close()

    skeleton = np.array(frames, dtype=np.float32)
    mean = skeleton.mean(axis=(0, 1), keepdims=True)
    std = skeleton.std(axis=(0, 1), keepdims=True) + 1e-6
    skeleton = (skeleton - mean) / std

    # íŒ¨ë”© ë˜ëŠ” ìë¥´ê¸°
    if skeleton.shape[0] < num_frames:
        pad = np.zeros((num_frames - skeleton.shape[0], 33, 4))
        skeleton = np.concatenate([skeleton, pad], axis=0)
    elif skeleton.shape[0] > num_frames:
        skeleton = skeleton[:num_frames]

    x = torch.tensor(skeleton, dtype=torch.float32).reshape(1, num_frames, -1)
    return x.to(DEVICE)

# -------------------------------------------------------------------
# ë¶„ë¥˜ í•¨ìˆ˜
# -------------------------------------------------------------------
def predict_exercise(video_path):
    x = extract_pose_from_video(video_path)
    print(f"ì…ë ¥ í…ì„œ shape: {x.shape}")
    with torch.no_grad():
        outputs = model(x)
        probs = torch.softmax(outputs, dim=1)
        pred_class = torch.argmax(probs, dim=1).item()
        confidence = probs[0, pred_class].item()
    return inv_label_map[pred_class], confidence


# -------------------------------------------------------------------
# ë¡œê·¸ ê¸°ë¡ í•¨ìˆ˜
# -------------------------------------------------------------------
RESULTS_DIR = os.path.join(SCRIPTS_DIR, "results")
RESULTS_LOG = os.path.join(RESULTS_DIR, "results.jsonl")

def _log_result(row: dict):
    os.makedirs(RESULTS_DIR, exist_ok=True)
    with open(RESULTS_LOG, "a", encoding="utf-8") as f:
        f.write(json.dumps(row, ensure_ascii=False) + "\n")

# -------------------------------------------------------------------
# API ì—”ë“œí¬ì¸íŠ¸
# -------------------------------------------------------------------
@app.post("/analyze")
async def analyze(file: UploadFile = File(...)):
    suffix = os.path.splitext(file.filename or "")[1] or ".mp4"
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(await file.read())
        video_path = os.path.abspath(tmp.name)

    try:
        # 1ï¸âƒ£ ìš´ë™ ë¶„ë¥˜
        ex, conf = predict_exercise(video_path)
        print(f"ğŸ‹ï¸ ì˜ˆì¸¡ëœ ìš´ë™: {ex} (ì‹ ë¢°ë„ {conf*100:.2f}%)")

        if ex not in SCRIPTS:
            raise HTTPException(status_code=400, detail=f"ì˜ˆì¸¡ëœ ìš´ë™ ìŠ¤í¬ë¦½íŠ¸ ì—†ìŒ: {ex}")

        # 2ï¸âƒ£ í•´ë‹¹ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        out_fd, out_json_path = tempfile.mkstemp(prefix="mp_out_", suffix=".json")
        os.close(out_fd)
        out_json_path = os.path.abspath(out_json_path)

        script_path = SCRIPTS[ex]
        proc = subprocess.run(
            [sys.executable, script_path, "--video", video_path, "--out", out_json_path],
            capture_output=True, text=True, encoding="utf-8"
        )

        if proc.returncode != 0:
            raise HTTPException(status_code=500, detail=f"Script error: {proc.stderr}")

        # 3ï¸âƒ£ ê²°ê³¼ JSON ì½ê¸°
        if not os.path.exists(out_json_path):
            raise HTTPException(status_code=500, detail="ê²°ê³¼ JSONì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")

        with open(out_json_path, "r", encoding="utf-8") as f:
            out = json.load(f)

        rep = int(out.get("rep_count", 0))
        acc = int(out.get("avg_accuracy", 0))

        # 4ï¸âƒ£ ë¡œê·¸ ë° ë°˜í™˜
        row = {
            "exercise_type": ex,
            "rep_count": rep,
        }
        _log_result(row)

        return JSONResponse(content=row)

    finally:
        try:
            os.remove(video_path)
        except Exception:
            pass
