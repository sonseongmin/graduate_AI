import sys, os
sys.stdout.reconfigure(encoding='utf-8')
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

import os
import pandas as pd
import numpy as np
from tqdm import tqdm

# ------------------------------------------------------
# ê²½ë¡œ ì„¤ì •
# ------------------------------------------------------
BASE = r"C:\mycla\TransRAC-main\RepCountA"
CSV_DIR = os.path.join(BASE, "annotation")
SKELETON_DIR = os.path.join(CSV_DIR, "skeleton_npz")
SAVE_BASE = os.path.join(BASE, "npz_7class")

# ------------------------------------------------------
# í´ë˜ìŠ¤ alias ë§¤í•‘
# ------------------------------------------------------
alias_map = {
    "squant": "squat",
    "pull_up": "pullup", "pullups": "pullup",
    "push_up": "pushup", "pushups": "pushup",
    "jump_jack": "jumpjack", "jumpjacks": "jumpjack",
    "bench_pressing": "benchpress", "benchpressing": "benchpress",
    "front_raise": "frontraise", "frontraise": "frontraise",
    "sit_ups": "situp", "situps": "situp"
}

keep_classes = ["pullup", "pushup", "jumpjack", "squat", "benchpress", "frontraise", "situp"]


# ------------------------------------------------------
# CSV í•„í„°ë§
# ------------------------------------------------------
def filter_csv(csv_name):
    src = os.path.join(CSV_DIR, f"{csv_name}.csv")
    dst = os.path.join(CSV_DIR, f"{csv_name}_7class.csv")

    df = pd.read_csv(src)
    df["type"] = df["type"].astype(str).map(lambda s: alias_map.get(s.lower(), s.lower()))
    df = df[df["type"].isin(keep_classes)].reset_index(drop=True)
    df.to_csv(dst, index=False)
    print(f"âœ… {csv_name}.csv â†’ {csv_name}_7class.csv ì €ì¥ ì™„ë£Œ ({len(df)}ê°œ ìƒ˜í”Œ)")
    return dst


# ------------------------------------------------------
# skeleton_npz ë§¤ì¹­ (train/valid/test í•˜ìœ„ í´ë” íƒìƒ‰)
# ------------------------------------------------------
def make_split(csv_path, split_name):
    save_dir = os.path.join(SAVE_BASE, split_name)
    src_split_dir = os.path.join(SKELETON_DIR, split_name)
    os.makedirs(save_dir, exist_ok=True)

    df = pd.read_csv(csv_path)
    print(f"\nâ–¶ [{split_name.upper()}] {len(df)}ê°œ ìƒ˜í”Œ ì²˜ë¦¬ ì¤‘...")

    kept, skipped = 0, 0
    for _, row in tqdm(df.iterrows(), total=len(df)):
        label = str(row["type"]).lower()
        label = alias_map.get(label, label)
        video_name = str(row["name"]).replace(".mp4", "")

        # âœ… npz ê²½ë¡œ ìˆ˜ì • â€” í´ë˜ìŠ¤ í•˜ìœ„ í´ë”ê¹Œì§€ íƒìƒ‰
        src_npz = os.path.join(src_split_dir, label, f"{video_name}.npz")
        dst_npz = os.path.join(save_dir, f"{video_name}.npz")

        if not os.path.exists(src_npz):
            skipped += 1
            continue

        data = np.load(src_npz, allow_pickle=True)
        np.savez_compressed(dst_npz, **data)
        kept += 1

    print(f"âœ… {split_name}: {kept}ê°œ ì €ì¥ ì™„ë£Œ | ì œì™¸/ëˆ„ë½ {skipped}ê°œ")



# ------------------------------------------------------
# ì‹¤í–‰
# ------------------------------------------------------
if __name__ == "__main__":
    print("ğŸ“¦ 7-Class ë°ì´í„°ì…‹ ì •ì œ ì‹œì‘...")

    for split in ["train", "valid", "test"]:
        csv_path = filter_csv(split)
        make_split(csv_path, split)

    print("\nğŸ‰ ëª¨ë“  ë°ì´í„°ì…‹ ì •ì œ ì™„ë£Œ!")
